# ‚ö° FASE 2 ‚Äì SIMULA√á√ÉO DE TESTES (CARGA / ESTRESSE / LIMITE)

**Data:** 25/12/2024  
**Contexto:** Sistema em PostgreSQL, Windows Server, Hardware t√≠pico (i5/16GB)  
**Metodologia:** An√°lise te√≥rica baseada em arquitetura, sem execu√ß√£o real

---

## üìä PREMISSAS T√âCNICAS

### Hardware Base (Cen√°rio Realista)
- **CPU:** Intel i5-10400 (6 cores, 12 threads) @ 2.9GHz
- **RAM:** 16GB DDR4
- **Disco:** SSD SATA 500GB (550 MB/s read, 520 MB/s write)
- **Rede:** 1 Gbps Ethernet
- **OS:** Windows Server 2019/2022

### Software Stack
- **Python:** 3.11 (asyncio nativo)
- **PostgreSQL:** 15.x (local, default config)
- **Uvicorn:** 1 worker (conforme `iniciar_postgres.bat`)
- **Concorr√™ncia Ping:** 100 (config atual)
- **Concorr√™ncia SNMP:** 100 (config atual)

### Configura√ß√µes Atuais
```python
PING_INTERVAL_SECONDS = 30
PING_TIMEOUT_SECONDS = 2
PING_CONCURRENT_LIMIT = 100
SNMP_INTERVAL = 60
SNMP_SEMAPHORE = 100
```

---

## üß™ CEN√ÅRIOS DE TESTE

### CEN√ÅRIO 1: Crescimento de Dispositivos Monitorados

| Dispositivos | Comportamento Esperado | Limite Aproximado | Sintoma da Falha |
|--------------|------------------------|-------------------|------------------|
| **100** | ‚úÖ Perfeito. Ping completa em ~2s, SNMP em ~5s | N/A | N/A |
| **300** | ‚úÖ Est√°vel. Ping em ~4s, SNMP em ~10s | N/A | Nenhum |
| **500** | ‚úÖ Bom. Ping em ~6s, SNMP em ~15s | CPU ~40% | Leve aumento de lat√™ncia |
| **800** | ‚ö†Ô∏è Aceit√°vel. Ping em ~10s, SNMP em ~25s | CPU ~65% | Pings come√ßam a atrasar |
| **1000** | ‚ö†Ô∏è Limite. Ping em ~12s, SNMP em ~30s | CPU ~80% | Timeouts ocasionais |
| **1500** | ‚ùå Degrada√ß√£o. Ping em ~20s, SNMP em ~50s | CPU ~95% | Timeouts frequentes, UI lenta |
| **2000+** | ‚ùå Colapso. Ping n√£o completa no intervalo | CPU 100% | Sistema trava, DB locks |

**Gargalo Principal:** CPU (processamento de ICMP + SNMP)  
**Componente que Falha Primeiro:** Pinger (timeouts acumulam)

**C√°lculo T√©cnico:**
```
Ping por dispositivo: ~20ms (ICMP) + ~10ms (DB write) = 30ms
Com concorr√™ncia 100: 1000 devices / 100 = 10 batches
Tempo total: 10 batches √ó 30ms √ó 2 (overhead) = ~600ms (ideal)
Real com network jitter: ~10-12s para 1000 devices
```

---

### CEN√ÅRIO 2: Aumento de Frequ√™ncia de Ping

**Baseline:** 30s (atual)

| Intervalo | Dispositivos | Comportamento | Limite | Sintoma |
|-----------|--------------|---------------|--------|---------|
| **30s** | 800 | ‚úÖ Est√°vel | CPU ~65% | Nenhum |
| **15s** | 800 | ‚ö†Ô∏è Tenso | CPU ~85% | DB writes aumentam 2x |
| **10s** | 800 | ‚ùå Cr√≠tico | CPU ~95% | Pings atrasam, logs acumulam |
| **5s** | 800 | ‚ùå Imposs√≠vel | CPU 100% | Sistema n√£o acompanha |

**Gargalo:** CPU + Disco (writes no PostgreSQL)

**C√°lculo de Writes:**
```
800 devices √ó 2 pings/min (30s) = 1600 writes/min = ~27 writes/s
800 devices √ó 12 pings/min (5s) = 9600 writes/min = 160 writes/s

PostgreSQL em SSD SATA: ~5000 IOPS
Mas com √≠ndices + WAL: efetivo ~2000 writes/s
Conclus√£o: 160 writes/s √© vi√°vel, mas CPU n√£o aguenta processar
```

---

### CEN√ÅRIO 3: Escritas Intensivas no Banco

**Teste:** Simular 1 m√™s de logs para 500 dispositivos

| Per√≠odo | Registros Totais | Tamanho Estimado | Comportamento |
|---------|------------------|------------------|---------------|
| **1 dia** | 1.4M pings | ~70 MB | ‚úÖ Normal |
| **1 semana** | 10M pings | ~500 MB | ‚úÖ Est√°vel |
| **1 m√™s** | 43M pings | ~2.1 GB | ‚ö†Ô∏è Queries lentas sem √≠ndices |
| **3 meses** | 130M pings | ~6.5 GB | ‚ö†Ô∏è Vacuum necess√°rio |
| **6 meses** | 260M pings | ~13 GB | ‚ùå Precisa particionamento |

**Gargalo:** Tamanho da tabela `ping_logs`

**Impacto em Queries:**
```sql
-- Query t√≠pica do dashboard (√∫ltimos 24h)
SELECT * FROM ping_logs 
WHERE device_id = 123 AND timestamp > NOW() - INTERVAL '24 hours'
ORDER BY timestamp DESC LIMIT 100;

Sem √≠ndice em (device_id, timestamp):
- 1M rows: ~200ms
- 10M rows: ~2s
- 43M rows: ~8s (INACEIT√ÅVEL)

Com √≠ndice composto:
- 43M rows: ~50ms ‚úÖ
```

**Solu√ß√£o Atual:** 
- ‚úÖ √çndice em `timestamp DESC` existe
- ‚úÖ Limpeza autom√°tica de 30 dias (reduz para ~43M max)
- ‚ö†Ô∏è Falta √≠ndice composto `(device_id, timestamp)`

---

### CEN√ÅRIO 4: Leitura Simult√¢nea de Gr√°ficos

**Teste:** 10 usu√°rios acessando dashboard simultaneamente

| Usu√°rios | Queries/s | Comportamento | Limite | Sintoma |
|----------|-----------|---------------|--------|---------|
| **1** | ~5 | ‚úÖ Instant√¢neo (<100ms) | CPU ~5% | Nenhum |
| **5** | ~25 | ‚úÖ R√°pido (~200ms) | CPU ~15% | Nenhum |
| **10** | ~50 | ‚úÖ Bom (~500ms) | CPU ~30% | Leve delay |
| **20** | ~100 | ‚ö†Ô∏è Lento (~1.5s) | CPU ~60% | Gr√°ficos demoram |
| **50** | ~250 | ‚ùå Travado (~5s+) | CPU ~90% | Timeout no frontend |

**Gargalo:** PostgreSQL query processing + JSON serialization

**Queries Mais Pesadas:**
1. **Dashboard principal:** 8 queries (torres, equipamentos, logs recentes, stats)
2. **Gr√°fico de lat√™ncia:** 1 query agregada (AVG por hora, √∫ltimos 7 dias)
3. **Mapa de rede:** 2 queries (posi√ß√µes + status)

**Otimiza√ß√£o Atual:**
- ‚úÖ Queries usam √≠ndices
- ‚ùå Sem cache (Redis desabilitado)
- ‚ùå Sem pagina√ß√£o em alguns endpoints

**Potencial com Cache:**
```
Dashboard sem cache: 500ms
Dashboard com Redis (60s TTL): 50ms (10x mais r√°pido)
```

---

### CEN√ÅRIO 5: Processamento da "IA Leve" (Synthetic Agent)

**Baseline:** 3 targets (Google DNS, Cloudflare, etc), check a cada 5 min

| Targets | Intervalo | Comportamento | Limite | Sintoma |
|---------|-----------|---------------|--------|---------|
| **3** | 5 min | ‚úÖ Impercept√≠vel | CPU <1% | Nenhum |
| **10** | 5 min | ‚úÖ Leve | CPU ~2% | Nenhum |
| **50** | 5 min | ‚ö†Ô∏è Moderado | CPU ~10% | Baseline training lento |
| **100** | 5 min | ‚ùå Pesado | CPU ~25% | Queries de agrega√ß√£o demoram |

**Gargalo:** Query de agrega√ß√£o com `EXTRACT(hour, ...)` em milh√µes de rows

**Query Cr√≠tica:**
```sql
SELECT target, EXTRACT(hour FROM timestamp) AS hour,
       AVG(latency_ms), COUNT(*)
FROM synthetic_logs
WHERE timestamp >= NOW() - INTERVAL '14 days'
GROUP BY target, EXTRACT(hour FROM timestamp);
```

**Performance:**
- 10k logs: ~50ms ‚úÖ
- 100k logs: ~500ms ‚úÖ
- 1M logs: ~5s ‚ö†Ô∏è
- 10M logs: ~50s ‚ùå

**Solu√ß√£o:** Limitar reten√ß√£o de `synthetic_logs` para 7 dias (n√£o 30)

---

## üî• CEN√ÅRIO EXTREMO: "Black Friday"

**Situa√ß√£o:** Todos os fatores de estresse simultaneamente

```
- 1000 dispositivos
- Ping a cada 15s
- 50 usu√°rios no dashboard
- 20 targets do Synthetic Agent
- 30 dias de logs acumulados
```

### Resultado Esperado

| Componente | Uso | Status |
|------------|-----|--------|
| **CPU** | 95-100% | ‚ùå Saturado |
| **RAM** | 8-10 GB | ‚ö†Ô∏è Alto mas OK |
| **Disco I/O** | 80% | ‚ö†Ô∏è Gargalo |
| **PostgreSQL** | 200 conex√µes | ‚ùå Pool esgotado |
| **Network** | 50 Mbps | ‚úÖ OK |

**Sintomas:**
1. Dashboard demora 10-15s para carregar
2. Pings atrasam 30-60s
3. SNMP para de funcionar (timeout)
4. Alertas do Telegram atrasam
5. Usu√°rios reportam "sistema travado"

**Ponto de Falha:** PostgreSQL connection pool (default 20 conex√µes)

---

## üìà AN√ÅLISE DE GARGALOS POR COMPONENTE

### 1. CPU

**Uso por Processo:**
- Pinger: 40-50% (em 1000 devices)
- SNMP Monitor: 20-30%
- Uvicorn/FastAPI: 10-15%
- PostgreSQL: 15-20%
- Synthetic Agent: 5-10%

**Limite:** ~800-1000 devices com config atual

**Escala:** Linear at√© 500, depois degrada exponencialmente

---

### 2. Mem√≥ria (RAM)

**Uso Estimado:**
- Python process: 500 MB (base)
- Asyncio tasks (1000 devices): +1.5 GB
- PostgreSQL shared_buffers (default 128MB): +128 MB
- OS + outros: 2 GB

**Total:** ~4-5 GB para 1000 devices

**Limite:** N√£o √© gargalo at√© 2000+ devices

---

### 3. Disco (I/O)

**Writes por Segundo (1000 devices, 30s interval):**
```
Ping logs: 33 writes/s
Traffic logs (SNMP 60s): 16 writes/s
Synthetic logs: 0.1 writes/s
Total: ~50 writes/s
```

**SSD SATA:** Aguenta 5000 IOPS, ent√£o I/O n√£o √© gargalo

**Mas:** PostgreSQL WAL + fsync pode criar micro-stalls

---

### 4. PostgreSQL

**Conex√µes Simult√¢neas:**
- Pinger: 1 conex√£o (pool interno)
- SNMP: 1 conex√£o
- Uvicorn: at√© 20 (default pool)
- Synthetic Agent: 1

**Total:** ~25 conex√µes pico

**Limite Default:** 100 conex√µes (OK)

**Gargalo Real:** Query performance sem √≠ndices adequados

---

### 5. Rede

**Tr√°fego Estimado (1000 devices):**
- ICMP pings: ~1 KB/device = 1 MB/30s = ~33 KB/s
- SNMP queries: ~500 bytes/device = 500 KB/60s = ~8 KB/s
- HTTP (dashboard): ~100 KB/request √ó 10 users = 1 MB/s

**Total:** ~1.5 MB/s = 12 Mbps

**Limite:** N√£o √© gargalo (1 Gbps dispon√≠vel)

---

## üéØ RESUMO DOS LIMITES

| M√©trica | Limite Confort√°vel | Limite M√°ximo | Sintoma de Falha |
|---------|-------------------|---------------|------------------|
| **Dispositivos** | 500 | 1000 | Timeouts de ping |
| **Intervalo Ping** | 30s | 15s | CPU saturado |
| **Usu√°rios Simult√¢neos** | 10 | 20 | Dashboard lento |
| **Reten√ß√£o de Logs** | 30 dias | 90 dias | Queries lentas |
| **Targets Synthetic** | 10 | 50 | Training demorado |

---

## üî¨ COMPONENTE QUE "CAI PRIMEIRO"

### Em Ordem de Falha

1. **Pinger** (CPU bound) - Falha em ~1000 devices
2. **SNMP Monitor** (Network + CPU) - Falha em ~800 devices
3. **PostgreSQL Queries** (Disk I/O) - Degrada em ~60 dias de logs
4. **Dashboard** (Serialization) - Lento com 20+ usu√°rios
5. **Synthetic Agent** (Agrega√ß√£o) - Lento com 100+ targets

---

## ‚ö†Ô∏è AVISOS IMPORTANTES

### O Que Estes N√∫meros N√ÉO S√£o

‚ùå Benchmarks reais  
‚ùå Garantias de performance  
‚ùå Resultados de testes de carga  

### O Que Estes N√∫meros S√ÉO

‚úÖ Estimativas t√©cnicas plaus√≠veis  
‚úÖ Baseadas em an√°lise de c√≥digo  
‚úÖ Considerando hardware t√≠pico  
‚úÖ √öteis para planejamento de capacidade  

---

## üéì CONCLUS√ïES T√âCNICAS

### Pontos Fortes

‚úÖ **Arquitetura ass√≠ncrona** permite alta concorr√™ncia  
‚úÖ **PostgreSQL** escala melhor que SQLite  
‚úÖ **Batch pinging** (icmplib multiping) √© muito eficiente  
‚úÖ **Semaphores** evitam sobrecarga de rede  

### Pontos Fracos

‚ö†Ô∏è **CPU single-threaded** limita escala (Python GIL)  
‚ö†Ô∏è **Sem cache** (Redis) desperdi√ßa CPU em queries repetidas  
‚ö†Ô∏è **√çndices incompletos** causam queries lentas  
‚ö†Ô∏è **1 worker Uvicorn** limita throughput HTTP  

### Limite Realista Atual

**Configura√ß√£o Atual:** 500-800 devices confortavelmente  
**Com Otimiza√ß√µes (Fase 3):** 1000-1500 devices  
**Com Arquitetura Distribu√≠da:** 5000+ devices (futuro)

---

## üìä PR√ìXIMOS PASSOS

Fase 3 ir√° analisar estes resultados e propor:
1. Otimiza√ß√µes de √≠ndices
2. Implementa√ß√£o de cache
3. Ajustes de configura√ß√£o
4. Melhorias incrementais

**Foco:** Maximizar performance sem mudan√ßas arquiteturais dr√°sticas.
